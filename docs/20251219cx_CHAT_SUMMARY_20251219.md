# 99AI-ANKI 部署与容量评估对话总结（2025-12-19）

聚焦：部署方式选择、前后端如何拆分、域名路径 vs 子域名方案、以及 4 核 8G 单机的容量预估与影响因素。

## 1. 部署方式选择：CVM + GitHub Actions vs Docker + TKE

### 结论（针对当前阶段）
- **优先推荐：CVM + GitHub Actions**，但“运行方式”尽量采用 **Docker/Compose**（在 CVM 上用容器跑服务）。
- **TKE（Kubernetes）** 更适合在你明确需要 **高可用、多副本、水平扩展、滚动发布**，且团队具备 K8s 运维/排障能力时再上。

### 关键理由
- 99AI-ANKI 仓库呈现多端/多服务形态：`admin`（前端）、`service`（后端 NestJS）、`chat`（前端/端或单独构建链路）。
- 你仓库里已经存在容器化/编排的基础（例如 `AIWebQuickDeploy/` 与 `service/` 下的 Docker/Compose 相关文件）。
- 以“**快速上线、易维护、可回滚**”为优先时：
  - CVM + Actions 学习曲线低、上手快。
  - 用 Docker/Compose 可以最大化环境一致性，并为未来迁移到 TKE 做铺垫。

### 适用场景建议
- **中小型项目、验证期、快速上线**：CVM + Actions（建议容器化运行）。
- **商业 SaaS/高并发/强高可用诉求**：Docker + TKE。

---

## 2. “部署两个”：前后端怎么拆？要不要分开？

### 关键理解
- 前端：构建产物是静态文件（HTML/CSS/JS），适合 **Nginx / 对象存储 / CDN**。
- 后端：常驻进程（NestJS/Node），提供 API，需要 **进程管理或容器运行**。
- “前后端分开部署”不等于“两台机器”，最常见的是：
  - **同一台服务器**上跑两个服务（不同端口/不同容器/不同进程）
  - 统一入口由 Nginx 负责转发。

### 两种常见架构

#### 方案 A（推荐：单机最省心）
- **同一台 CVM**：Nginx + 前端静态 + 后端 service
- Nginx 路由：
  - `/` → 前端静态站点
  - `/api` → 反向代理到后端（如 `http://127.0.0.1:3000`）
- 优点：
  - 不需要跨域（少折腾 CORS/cookie 域）
  - 一个域名一张证书，运维简单

#### 方案 B（前端真分离：更标准但更复杂）
- 前端：COS + CDN（或其他静态托管）
- 后端：CVM/TKE
- 域名：
  - `admin.example.com`（前端）
  - `api.example.com`（后端）
- 优点：
  - 前端带宽压力更低、发布更独立
- 代价：
  - 需要处理跨域（CORS）及鉴权细节

---

## 3. 同域名路径分流 vs 子域名分流：哪种更好？

### 结论（对当前阶段的推荐）
- **优先选择：同域名 + 路径分流**（`example.com` + `/api`）。
- 后续如果要上 COS+CDN 或 TKE，再迁移到 **子域名分流**（`admin.example.com` / `api.example.com`）。

### 路径分流更适合当前阶段的原因
- 前端请求 API 不算跨域：CORS、cookie 域、鉴权回调等问题大幅减少。
- 运维更简单：一个域名、一套证书、一个 Nginx 入口。
- 很适合“单机 + Compose”的部署方式。

### 子域名分流更适合的场景
- 前端放 COS+CDN，需要独立托管与缓存策略。
- API 与前端需要独立扩缩容、灰度、网关/WAF/限流策略。

---

## 4. 4 核 8G 单机：能撑多少“在线用户”？（区间估算）

> 说明：这里的“在线”更建议按 **“活跃用户”** 或 **“请求吞吐（RPS）”** 来衡量。
> 你已确认：LLM/向量化/Embedding/OCR 等由 **外部 FastAPI 接口调用**（你机器主要是转发与业务编排），这会显著降低本机 CPU 压力。

### 4.1 数据库在同机 vs 云上（两种情况）

#### 情况 A：DB/Redis 同机（更吃紧）
- 瓶颈更容易在：磁盘 IO、DB CPU、内存缓存互抢。
- 经验区间（以轻业务为主）：
  - 稳态吞吐：**约 30–120 RPS**
  - 同时“活跃操作”的在线用户：**约 200–800**

#### 情况 B：云数据库/云 Redis（更推荐）
- 单机更专注跑应用层（service + Nginx）。
- 经验区间（以轻业务为主）：
  - 稳态吞吐：**约 80–250 RPS**
  - 同时“活跃操作”的在线用户：**约 500–2000**

### 4.2 在线行为类型：轻交互 vs 重处理（两种情况）

#### 情况 1：纯浏览/轻交互（登录、列表、CRUD；LLM 外部调用）
- 云 DB：可按 **500–2000 活跃在线** 做目标规划。
- 同机 DB：更稳妥按 **200–800 活跃在线**。

#### 情况 2：PDF/AI 处理为主（上传、解析、切分、入库等）
- 即使 LLM 在外部，单机仍要承担：上传 IO、解析/切分、写库、任务调度。
- 更合理的容量指标是“同时处理任务数”：
  - 重任务并发：**约 5–20**（建议强制排队/限流）
  - 同时在线用户：可能仍有 **200–1000**，但体验取决于是否异步化（队列 + 进度查询）。

### 4.3 chat 是否 WebSocket：你当时不确定（如何影响）
- 如果是 **WebSocket 长连接**：
  - “连接数”可上到几千甚至更高，但压力由“消息频率/广播”决定。
  - 群聊广播会显著放大转发成本。
- 如果是 **HTTP 轮询/短连接**：
  - 压力更直接体现在 RPS；轮询频率越高越吃后端。

快速自查方式：
- 浏览器开发者工具 Network 看是否存在 `ws://` 或 `wss://` 连接。
- 或检查 Nginx 是否有 Upgrade/Connection 相关反代配置（有则多半是 WS）。

---

## 5. 可执行的“保守规划建议”（单机 4C8G）

- 若使用云 DB/Redis + 以轻交互为主：对外可按 **~1000 活跃在线** 做保守规划。
- 若 DB 同机或重任务占比高：建议按 **~300–500 活跃在线** 做更稳的规划。
- 若 PDF/处理任务是核心能力：建议必须引入 **队列/并发上限/限流**，避免峰值雪崩。

---

## 6. 后续可选动作（当时提出的下一步）

- 输出一份“CVM + Actions + Docker Compose”的最小可用部署清单（安装项、目录结构、回滚方式）。
- 给出 Nginx 入口建议（`/` 前端静态，`/api` 反代后端），并按实际端口/服务名落地。
- 给出压测方案（例如 k6/Artillery）：
  - 目标：测出你当前业务真实可稳住的 RPS、P95 延迟、活跃在线区间。

